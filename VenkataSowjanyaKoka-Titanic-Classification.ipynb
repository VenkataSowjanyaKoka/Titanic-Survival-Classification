{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for structured data we use Spark SQL, SparkSession acts a pipeline between data and sql statements\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparksession is like a class and we need to create an instance of a class to utilize\n",
    "spark = SparkSession.builder.appName(\"Train_Data_Logistic_Regression\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To assign dummy values to the string variables\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For creation of a vector of input variables\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For assigning the dummy variables\n",
    "from pyspark.ml.feature import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the logistic regression model\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the csv file data\n",
    "Train_DF = spark.read.csv(\"/Users/sowjanyakoka/Desktop/Spring2020/MachineLearning/Titanics.csv\", inferSchema = True, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (891, 12)\n"
     ]
    }
   ],
   "source": [
    "#Seeing the shape of the dataset\n",
    "print(\"Shape:\", (Train_DF.count(), len(Train_DF.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Looking at the top 10 rows data of the dataset\n",
    "Train_DF.show(10, truncate = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------+------------------+------------------------------------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|summary|PassengerId      |Survived           |Pclass            |Name                                            |Sex   |Age               |SibSp             |Parch              |Ticket            |Fare             |Cabin|Embarked|\n",
      "+-------+-----------------+-------------------+------------------+------------------------------------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|count  |891              |891                |891               |891                                             |891   |714               |891               |891                |891               |891              |204  |891     |\n",
      "|mean   |446.0            |0.3838383838383838 |2.308641975308642 |null                                            |null  |29.69911764705882 |0.5230078563411896|0.38159371492704824|260318.54916792738|32.2042079685746 |null |null    |\n",
      "|stddev |257.3538420152301|0.48659245426485753|0.8360712409770491|null                                            |null  |14.526497332334035|1.1027434322934315|0.8060572211299488 |471609.26868834975|49.69342859718089|null |null    |\n",
      "|min    |1                |0                  |1                 |\"Andersson, Mr. August Edvard (\"\"Wennerstrom\"\")\"|female|0.42              |0                 |0                  |110152            |0.0              |A10  |C       |\n",
      "|max    |891              |1                  |3                 |van Melkebeke, Mr. Philemon                     |male  |80.0              |8                 |6                  |WE/P 5735         |512.3292         |T    |S       |\n",
      "+-------+-----------------+-------------------+------------------+------------------------------------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Looking at the descriptive statistics of the dataset\n",
    "Train_DF.describe().show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the above statistics we can clearly see that age and cabin columns have null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for number of null values in age column\n",
    "Train_DF.where(Train_DF['Age'].isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|Age               |\n",
      "+-------+------------------+\n",
      "|count  |714               |\n",
      "|mean   |29.69911764705882 |\n",
      "|stddev |14.526497332334035|\n",
      "|min    |0.42              |\n",
      "|max    |80.0              |\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Finding the average value of age column\n",
    "Train_DF.describe('Age').show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "687"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for null values in Cabin column\n",
    "Train_DF.where(Train_DF['Cabin'].isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing the null values in age column with average value of age column\n",
    "Train_DF = Train_DF.fillna({'Age':29.69911764705882})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Again Checking for null values in age column\n",
    "Train_DF.where(Train_DF['Age'].isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|          Cabin|count|\n",
      "+---------------+-----+\n",
      "|           null|  687|\n",
      "|    C23 C25 C27|    4|\n",
      "|        B96 B98|    4|\n",
      "|             G6|    4|\n",
      "|           E101|    3|\n",
      "|        C22 C26|    3|\n",
      "|            F33|    3|\n",
      "|             F2|    3|\n",
      "|              D|    3|\n",
      "|            D17|    2|\n",
      "|           E121|    2|\n",
      "|           C123|    2|\n",
      "|            B20|    2|\n",
      "|            B28|    2|\n",
      "|            E25|    2|\n",
      "|            C65|    2|\n",
      "|            D20|    2|\n",
      "|            B22|    2|\n",
      "|            E67|    2|\n",
      "|           C126|    2|\n",
      "|            B18|    2|\n",
      "|            C52|    2|\n",
      "|          F G73|    2|\n",
      "|            C83|    2|\n",
      "|             F4|    2|\n",
      "|            B77|    2|\n",
      "|            E24|    2|\n",
      "|            D33|    2|\n",
      "|           C124|    2|\n",
      "|            C92|    2|\n",
      "|             E8|    2|\n",
      "|            D36|    2|\n",
      "|            C68|    2|\n",
      "|             C2|    2|\n",
      "|            D26|    2|\n",
      "|            D35|    2|\n",
      "|B57 B59 B63 B66|    2|\n",
      "|             B5|    2|\n",
      "|            E33|    2|\n",
      "|            B49|    2|\n",
      "|            B35|    2|\n",
      "|    B51 B53 B55|    2|\n",
      "|           C125|    2|\n",
      "|            E44|    2|\n",
      "|        B58 B60|    2|\n",
      "|            C93|    2|\n",
      "|            C78|    2|\n",
      "|            A23|    1|\n",
      "|            B79|    1|\n",
      "|           C110|    1|\n",
      "|             D7|    1|\n",
      "|            C95|    1|\n",
      "|            B39|    1|\n",
      "|            D21|    1|\n",
      "|             A6|    1|\n",
      "|            E31|    1|\n",
      "|           C128|    1|\n",
      "|            C90|    1|\n",
      "|            B30|    1|\n",
      "|            E50|    1|\n",
      "|           C104|    1|\n",
      "|            B50|    1|\n",
      "|              T|    1|\n",
      "|            A36|    1|\n",
      "|            D48|    1|\n",
      "|          F E69|    1|\n",
      "|            D28|    1|\n",
      "|           C103|    1|\n",
      "|            D15|    1|\n",
      "|            D45|    1|\n",
      "|        C62 C64|    1|\n",
      "|            B38|    1|\n",
      "|            E63|    1|\n",
      "|            C50|    1|\n",
      "|            C45|    1|\n",
      "|            E77|    1|\n",
      "|            B80|    1|\n",
      "|            A19|    1|\n",
      "|             B4|    1|\n",
      "|            E10|    1|\n",
      "|            C54|    1|\n",
      "|            C82|    1|\n",
      "|            D46|    1|\n",
      "|            E49|    1|\n",
      "|          F G63|    1|\n",
      "|            A32|    1|\n",
      "|            B71|    1|\n",
      "|            C87|    1|\n",
      "|            C86|    1|\n",
      "|            B86|    1|\n",
      "|             D9|    1|\n",
      "|            A20|    1|\n",
      "|            B94|    1|\n",
      "|        D10 D12|    1|\n",
      "|            D49|    1|\n",
      "|            D37|    1|\n",
      "|           B102|    1|\n",
      "|            A14|    1|\n",
      "|             A7|    1|\n",
      "|             C7|    1|\n",
      "|           C111|    1|\n",
      "|            E12|    1|\n",
      "|            C30|    1|\n",
      "|            A16|    1|\n",
      "|            B69|    1|\n",
      "|            B19|    1|\n",
      "|            A26|    1|\n",
      "|            C99|    1|\n",
      "|            E38|    1|\n",
      "|            C46|    1|\n",
      "|            C85|    1|\n",
      "|           C106|    1|\n",
      "|            D47|    1|\n",
      "|             B3|    1|\n",
      "|            E68|    1|\n",
      "|            A34|    1|\n",
      "|            E58|    1|\n",
      "|            E46|    1|\n",
      "|            E36|    1|\n",
      "|            A10|    1|\n",
      "|            D30|    1|\n",
      "|            A31|    1|\n",
      "|            B37|    1|\n",
      "|            E40|    1|\n",
      "|           C148|    1|\n",
      "|            C91|    1|\n",
      "|            D19|    1|\n",
      "|            A24|    1|\n",
      "|            E34|    1|\n",
      "|            D50|    1|\n",
      "|           B101|    1|\n",
      "|            C47|    1|\n",
      "|            E17|    1|\n",
      "|            B73|    1|\n",
      "|             A5|    1|\n",
      "|            C32|    1|\n",
      "|            F38|    1|\n",
      "|            D11|    1|\n",
      "|             D6|    1|\n",
      "|           C101|    1|\n",
      "|           C118|    1|\n",
      "|            B78|    1|\n",
      "|            C49|    1|\n",
      "|            C70|    1|\n",
      "|            D56|    1|\n",
      "|        B82 B84|    1|\n",
      "|            B42|    1|\n",
      "|            B41|    1|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Train_DF.groupBy('Cabin').count().orderBy('count', ascending = False).show(Train_DF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since there are more than 50% null values in cabin column we do not consider replacing the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Survived|count|\n",
      "+--------+-----+\n",
      "|       1|  342|\n",
      "|       0|  549|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To check frequency of data by Survival\n",
    "Train_DF.groupBy('Survived').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|Pclass|count|\n",
      "+------+-----+\n",
      "|     1|  216|\n",
      "|     3|  491|\n",
      "|     2|  184|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To check frequency of data by type of Pclass\n",
    "Train_DF.groupBy('Pclass').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|   Sex|count|\n",
      "+------+-----+\n",
      "|female|  314|\n",
      "|  male|  577|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To check frequency of data by type of Gender\n",
    "Train_DF.groupBy('Sex').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Embarked|count|\n",
      "+--------+-----+\n",
      "|       Q|   78|\n",
      "|       C|  168|\n",
      "|       S|  645|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To check frequency of data by age\n",
    "Train_DF.groupBy('Embarked').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+-------------+------------------+------------------+-------------------+------------------+------------------+\n",
      "|Survived|  avg(PassengerId)|avg(Survived)|       avg(Pclass)|          avg(Age)|         avg(SibSp)|        avg(Parch)|         avg(Fare)|\n",
      "+--------+------------------+-------------+------------------+------------------+-------------------+------------------+------------------+\n",
      "|       1|444.36842105263156|          1.0|1.9502923976608186| 28.54977812177503|0.47368421052631576|0.4649122807017544| 48.39540760233917|\n",
      "|       0| 447.0163934426229|          0.0|2.5318761384335153|30.415099646415896| 0.5537340619307832|0.3296903460837887|22.117886885245877|\n",
      "+--------+------------------+-------------+------------------+------------------+-------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To check average of data by number of people survival status \n",
    "Train_DF.groupBy('Survived').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (891, 12)\n"
     ]
    }
   ],
   "source": [
    "#Question(1).What is the shape of the data contained in training.csv?\n",
    "#=====================================================================\n",
    "#(Answer):The shape of the data is the number of rows and columns (m = rows, n = columns) present in the dataset\n",
    "#Seeing the shape of the dataset\n",
    "print(\"Shape:\", (Train_DF.count(), len(Train_DF.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features recorded for each automobile are : ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "#Question(2).What features (or attributes) are recorded for each passenger in training.csv?\n",
    "#(Answer):The features recorded for each automobile can be known by the column names in the dataframe\n",
    "Train_DF_Features = Train_DF.columns\n",
    "print(\"The features recorded for each automobile are :\", Train_DF_Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = false)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Question3:Provide a schema of the columns to be included in your model for this assignment. \n",
    "#Looking at the schema of the dataset\n",
    "Train_DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Age: double (nullable = false)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Schema for the model\n",
    "model_schema = Train_DF.select('Survived','Pclass','Age','Sex','Embarked')\n",
    "model_schema.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question3.Provide a schema of the columns to be included in your model for this assignment. \n",
    "#Comment on columns that may require transformation(s). \n",
    "#An example of transformation is that of creating dummy variables. \n",
    "#List these columns and explain why and what transformation is required. I\n",
    "#Include these comments in your notebook. \n",
    "#=======================================================================================\n",
    "#(Answer): The columns that we would be using for this model are,\n",
    "#Survived(Dependent Variable)\n",
    "#INDEPENDENT VARIABLES\n",
    "#Pclass(Categorical)\n",
    "#Sex(Categorical)\n",
    "#Age\n",
    "#Embarked(Categorical)\n",
    "#=======================================================================================\n",
    "#In order to perform a logistic regression we should have independent variables as numerical datatype values\n",
    "#So the columns to be transformed from categorical variable to numeric data are,\n",
    "#-Pclass\n",
    "#-Sex\n",
    "#-Embarked\n",
    "#The Pclass variable Pclass has three different categories 1,2,3 in order to use the column for logistic regression we need to create a Dummy Vector Variable using Encoder\n",
    "#The categorical variable Geneder has either male or female labels for which we assign a indexer say 0 for male and 1 for female and use encoder to create a significant dummy vector varibles\n",
    "#The embarked variable has three different labels Q,S,C for which first create string index and then assign respective numerical dummy vectors using encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+-------------+------------------+------------------+-------------------+------------------+------------------+\n",
      "|Survived|  avg(PassengerId)|avg(Survived)|       avg(Pclass)|          avg(Age)|         avg(SibSp)|        avg(Parch)|         avg(Fare)|\n",
      "+--------+------------------+-------------+------------------+------------------+-------------------+------------------+------------------+\n",
      "|       1|444.36842105263156|          1.0|1.9502923976608186| 28.54977812177503|0.47368421052631576|0.4649122807017544| 48.39540760233917|\n",
      "|       0| 447.0163934426229|          0.0|2.5318761384335153|30.415099646415896| 0.5537340619307832|0.3296903460837887|22.117886885245877|\n",
      "+--------+------------------+-------------+------------------+------------------+-------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Question(4):4.Comment on the balance of data in training.csv with regards to each input variable as well as your target variable. Support your comments with appropriate statistics.\n",
    "Train_DF.groupBy('Survived').mean().show()\n",
    "#people with an average of 28 are survived compared people above average of 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|Pclass|count|\n",
      "+------+-----+\n",
      "|     1|  216|\n",
      "|     3|  491|\n",
      "|     2|  184|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In case of balance in our original data \n",
    "#For Pclass we can see the data we have is biased towards a Pclass 3(which is third class passengers)\n",
    "Train_DF.groupBy('Pclass').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "| Age|count|\n",
      "+----+-----+\n",
      "| 8.0|    4|\n",
      "|70.0|    2|\n",
      "| 7.0|    3|\n",
      "|20.5|    1|\n",
      "|49.0|    6|\n",
      "|29.0|   20|\n",
      "|40.5|    2|\n",
      "|64.0|    2|\n",
      "|47.0|    9|\n",
      "|42.0|   13|\n",
      "|24.5|    1|\n",
      "|44.0|    9|\n",
      "|35.0|   18|\n",
      "|62.0|    4|\n",
      "|18.0|   26|\n",
      "|80.0|    1|\n",
      "|34.5|    1|\n",
      "|39.0|   14|\n",
      "| 1.0|    7|\n",
      "|45.5|    2|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In case of balance in our original data \n",
    "#For Age we can see the data we have is balanced towards as it has people of all age categories\n",
    "Train_DF.groupBy('Age').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|   Sex|count|\n",
      "+------+-----+\n",
      "|female|  314|\n",
      "|  male|  577|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In case of balance in our original data \n",
    "#For Sex we can see the data we have is biased towards Male because there are more male passengers data than female\n",
    "Train_DF.groupBy('Sex').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Embarked|count|\n",
      "+--------+-----+\n",
      "|       Q|   78|\n",
      "|       C|  168|\n",
      "|       S|  645|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In case of balance in our original data \n",
    "#For Embarked we can see the data we have is biased towards s for Southampton, because there are more records with port of embarkation as S\n",
    "Train_DF.groupBy('Embarked').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Survived|count|\n",
      "+--------+-----+\n",
      "|       1|  342|\n",
      "|       0|  549|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In case of balance in our original data \n",
    "#For Survived we can see the data we have is biased towards people not survived, because there are more records Survived =0 compared to survival= 1\n",
    "Train_DF.groupBy('Survived').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question(4)a: Transformations\n",
    "#a.Perform the transformations, if any, identified in step # 3. Perform feature engineering if and where needed, including Vectorization of relevant input variables. Provide a printout of the schema of your feature-engineered data.\n",
    "#(Answer):\n",
    "#Categorical values into numerical values automatically first for Pclass variables(Specification)\n",
    "#StringIndexer arguments = name of input columns and resulting column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4(a)Categorical values into numerical values automatically first for Gender variables(Specification)\n",
    "#StringIndexer arguments = name of input columns and resulting column\n",
    "Sex_Indexer = StringIndexer(inputCol = 'Sex', outputCol = 'Gender_Num').fit(Train_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4(a)Taking Categorical data and transforming\n",
    "Train_DF = Sex_Indexer.transform(Train_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+----------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Gender_Num|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+----------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|       0.0|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|       1.0|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|       1.0|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|       1.0|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|       0.0|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4(a)Checking if numbers are assingned\n",
    "Train_DF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|Gender_Num|count|\n",
      "+----------+-----+\n",
      "|       0.0|  577|\n",
      "|       1.0|  314|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4(a)To check count of data by type of gender after creating Gender_Num\n",
    "Train_DF.groupBy('Gender_Num').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4(a)Categorical values into numerical values automatically first for Pclass variables(Specification)\n",
    "#StringIndexer arguments = name of input columns and resulting column\n",
    "Embarked_Indexer = StringIndexer(inputCol = 'Embarked', outputCol = 'Embarked_Num').fit(Train_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4(a)Taking Categorical data and transforming\n",
    "Train_DF = Embarked_Indexer.transform(Train_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+----------+------------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Gender_Num|Embarked_Num|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+----------+------------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|       0.0|         0.0|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|       1.0|         1.0|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|       1.0|         0.0|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|       1.0|         0.0|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|       0.0|         0.0|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4(a)Checking if numbers are assingned\n",
    "Train_DF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|Embarked_Num|count|\n",
      "+------------+-----+\n",
      "|         0.0|  645|\n",
      "|         1.0|  168|\n",
      "|         2.0|   78|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4(a)To check count of data by type of embarkment after creating Embarked_Num\n",
    "Train_DF.groupBy('Embarked_Num').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+----------+------------+-------------------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Gender_Num|Embarked_Num|Pclass_Dummy_Vector|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+----------+------------+-------------------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|       0.0|         0.0|          (3,[],[])|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|       1.0|         1.0|      (3,[1],[1.0])|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|       1.0|         0.0|          (3,[],[])|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+----------+------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4(a)Check how many distinct values the variables have and assign right number of dummy variables for Pclass\n",
    "Pclass_Encoder = OneHotEncoder(inputCol = 'Pclass', outputCol = 'Pclass_Dummy_Vector')\n",
    "Train_DF = Pclass_Encoder.transform(Train_DF)\n",
    "Train_DF.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|Pclass_Dummy_Vector|count|\n",
      "+-------------------+-----+\n",
      "|      (3,[2],[1.0])|  184|\n",
      "|      (3,[1],[1.0])|  216|\n",
      "|          (3,[],[])|  491|\n",
      "+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Train_DF.groupBy('Pclass_Dummy_Vector').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+----------+------------+-------------------+-------------------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Gender_Num|Embarked_Num|Pclass_Dummy_Vector|Gender_Dummy_Vector|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+----------+------------+-------------------+-------------------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|       0.0|         0.0|          (3,[],[])|      (1,[0],[1.0])|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|       1.0|         1.0|      (3,[1],[1.0])|          (1,[],[])|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|       1.0|         0.0|          (3,[],[])|          (1,[],[])|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+----------+------------+-------------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4(a)Check how many distinct values the variables have and assign right number of dummy variables for Gender\n",
    "Gender_Encoder = OneHotEncoder(inputCol = 'Gender_Num', outputCol = 'Gender_Dummy_Vector')\n",
    "Train_DF = Gender_Encoder.transform(Train_DF)\n",
    "Train_DF.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|Gender_Dummy_Vector|count|\n",
      "+-------------------+-----+\n",
      "|      (1,[0],[1.0])|  577|\n",
      "|          (1,[],[])|  314|\n",
      "+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Train_DF.groupBy('Gender_Dummy_Vector').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+----------+------------+-------------------+-------------------+---------------------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Gender_Num|Embarked_Num|Pclass_Dummy_Vector|Gender_Dummy_Vector|Embarked_Dummy_Vector|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+----------+------------+-------------------+-------------------+---------------------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|       0.0|         0.0|          (3,[],[])|      (1,[0],[1.0])|        (2,[0],[1.0])|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|       1.0|         1.0|      (3,[1],[1.0])|          (1,[],[])|        (2,[1],[1.0])|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|       1.0|         0.0|          (3,[],[])|          (1,[],[])|        (2,[0],[1.0])|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+----------+------------+-------------------+-------------------+---------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4(a)Check how many distinct values the variables have and assign right number of dummy variables for Embarked\n",
    "Embarked_Encoder = OneHotEncoder(inputCol = 'Embarked_Num', outputCol = 'Embarked_Dummy_Vector')\n",
    "Train_DF = Embarked_Encoder.transform(Train_DF)\n",
    "Train_DF.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----+\n",
      "|Embarked_Dummy_Vector|count|\n",
      "+---------------------+-----+\n",
      "|        (2,[0],[1.0])|  645|\n",
      "|        (2,[1],[1.0])|  168|\n",
      "|            (2,[],[])|   78|\n",
      "+---------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Train_DF.groupBy('Embarked_Dummy_Vector').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = false)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- Gender_Num: double (nullable = false)\n",
      " |-- Embarked_Num: double (nullable = false)\n",
      " |-- Pclass_Dummy_Vector: vector (nullable = true)\n",
      " |-- Gender_Dummy_Vector: vector (nullable = true)\n",
      " |-- Embarked_Dummy_Vector: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking the Schema\n",
    "Train_DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4(a)Feature Engineering\n",
    "#import transformer to combine all variables into one column to perform linear regression btw output and variables\n",
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Assembler_Train_DF = VectorAssembler(inputCols = ['Age','Gender_Dummy_Vector','Pclass_Dummy_Vector','Embarked_Dummy_Vector'], outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_DF = Assembler_Train_DF.transform(Train_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = false)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- Gender_Num: double (nullable = false)\n",
      " |-- Embarked_Num: double (nullable = false)\n",
      " |-- Pclass_Dummy_Vector: vector (nullable = true)\n",
      " |-- Gender_Dummy_Vector: vector (nullable = true)\n",
      " |-- Embarked_Dummy_Vector: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##4(a)printout of the schema of your feature-engineered data.\n",
    "Train_DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset for generation of model\n",
    "Model_DF = Train_DF.select(['Survived','features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Schema of the model dataset\n",
    "Model_DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------------+\n",
      "|Survived|features                  |\n",
      "+--------+--------------------------+\n",
      "|0       |(7,[0,1,5],[22.0,1.0,1.0])|\n",
      "|1       |(7,[0,3,6],[38.0,1.0,1.0])|\n",
      "|1       |(7,[0,5],[26.0,1.0])      |\n",
      "+--------+--------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Model_DF.show(3, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question(4)b.To train and then test your model, split the data from training.csv into training and test datasets using an 80/20 split. \n",
    "#Like you did in step 4 above, comment on the balance of data in the training and test datasets. \n",
    "#Are they representative of the overall data? \n",
    "#What can you say about the balance in target classes in both the training and test datasets?\n",
    "#Answer)\n",
    "#Splitting of data for regression into required division\n",
    "Training_DF, Testing_DF = Model_DF.randomSplit([0.75,0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678\n"
     ]
    }
   ],
   "source": [
    "print(Training_DF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n"
     ]
    }
   ],
   "source": [
    "print(Testing_DF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Survived|count|\n",
      "+--------+-----+\n",
      "|       1|  272|\n",
      "|       0|  406|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#In training dataset there are about 270 survived passengers and 449 of unsurvived passengers\n",
    "Training_DF.groupBy('Survived').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Survived|count|\n",
      "+--------+-----+\n",
      "|       1|   70|\n",
      "|       0|  143|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#The testing dataset has about 72 survived passengers and 100 passengers who are not survived\n",
    "Testing_DF.groupBy('Survived').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This ensures we have a balance set of the target class (Survived) into the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question(4)c: Build and train the Logistic Regression model. \n",
    "#Generate a list of predictions for passengers survival status (survival = 1) based on the trained model. \n",
    "#Display actual, predicted, and probability values for the first 10 rows only. Based on these results, comment on the performance of the model?\n",
    "#Is the model predicting likelihood of survival with high probability? \n",
    "#Using Logistic Regression\n",
    "Log_Reg = LogisticRegression(labelCol = 'Survived').fit(Training_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating the predictions\n",
    "Training_Results = Log_Reg.evaluate(Training_DF).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------------------------------------+\n",
      "|Survived|prediction|probability                             |\n",
      "+--------+----------+----------------------------------------+\n",
      "|1       |1.0       |[0.21945587715809511,0.7805441228419049]|\n",
      "|1       |1.0       |[0.2243665398869764,0.7756334601130236] |\n",
      "|1       |1.0       |[0.2243665398869764,0.7756334601130236] |\n",
      "|1       |1.0       |[0.23956318504334329,0.7604368149566567]|\n",
      "|1       |1.0       |[0.2554501292095873,0.7445498707904127] |\n",
      "|1       |1.0       |[0.2992689360778693,0.7007310639221306] |\n",
      "|1       |1.0       |[0.2992689360778693,0.7007310639221306] |\n",
      "|1       |1.0       |[0.2992689360778693,0.7007310639221306] |\n",
      "|1       |1.0       |[0.2992689360778693,0.7007310639221306] |\n",
      "|1       |1.0       |[0.2992689360778693,0.7007310639221306] |\n",
      "+--------+----------+----------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Filtering predictions and trained results which are equal to 1\n",
    "#Applied a non-linear function to generate probability\n",
    "#So, in the above results, probability at the 0th index is for Status = 0 and probability as 1st index is for Status =1.\n",
    "Training_Results.filter(Training_Results['Survived']==1).filter(Training_Results['prediction']==1).select(['Survived','prediction','probability']).show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer: in the above 10 rows we can see that the actual survived value ansd predicted survival value are same for the top 10 rows.\n",
    "#So the second probabibility values are likely hood of survival which is predicted with high probability by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question:4(d)\n",
    "#d.\tUsing the test data from the 80/20 split, evaluate the performance of your trained model.\n",
    "#Compute and show the values for Accuracy, Recall, Precision, and an F1 score. \n",
    "#Comment of general usefulness of the model in predicting the survival status of passengers given their age, gender, pclass and embarked values. \n",
    "#Answer:\n",
    "#Generating the predicted values using test data\n",
    "#We can see that the model is pretty good and useful as its generating output with a high probability similar to actual data\n",
    "Results = Log_Reg.evaluate(Testing_DF).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------------------------------------+\n",
      "|Survived|prediction|probability                             |\n",
      "+--------+----------+----------------------------------------+\n",
      "|0       |1.0       |[0.23442044032462525,0.7655795596753747]|\n",
      "|0       |1.0       |[0.2992689360778693,0.7007310639221306] |\n",
      "|0       |1.0       |[0.2992689360778693,0.7007310639221306] |\n",
      "|0       |0.0       |[0.8017663671050823,0.19823363289491774]|\n",
      "|0       |0.0       |[0.8275007792065519,0.17249922079344812]|\n",
      "+--------+----------+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Applied a non-linear function to generate probability for test dataset\n",
    "Results.select('Survived','prediction','probability').show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since this is a classification problem, we will use a confusion matrix togauge the performance of the model.\n",
    "#Seeing the predicted values for test data which shows TP(True Positives),FP(False Positives),TN(True Negatives),FN(False Negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For number of True Positives\n",
    "TP = Results[(Results.Survived == 1) & (Results.prediction == 1)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For number of True Negatives\n",
    "TN = Results[(Results.Survived == 0) & (Results.prediction == 0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For number of False Positives(Actual=0,Predicted =1)\n",
    "FP = Results[(Results.Survived == 0) & (Results.prediction == 1)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For number of False Negatives(Actual=1,Predicted =0)\n",
    "FN = Results[(Results.Survived == 1) & (Results.prediction == 0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7981220657276995"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Manual computations\n",
    "Accuracy = (TP + TN)/(TP+TN+FP+FN)\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7285714285714285"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recall rate shows how much of the positive class cases we are able topredict correctly out of the total positive class observations.\n",
    "Recall = TP/(TP + FN)\n",
    "Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Precision rate talks about the number of true positives predicted correctly out of all the predicted positives observations:\n",
    "Precision = TP/(TP + FP)\n",
    "Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary of the model trained with training dataset\n",
    "Training_Summary = Log_Reg.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC: 0.8498533033903216\n"
     ]
    }
   ],
   "source": [
    "#Calculating ROC\n",
    "print(\"areaUnderROC: \" + str(Training_Summary.areaUnderROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7876106194690266\n",
      "0.7876106194690264\n",
      "0.7864204728666768\n",
      "0.7867617751311864\n"
     ]
    }
   ],
   "source": [
    "print(Training_Summary.accuracy)\n",
    "print(Training_Summary.weightedRecall)\n",
    "print(Training_Summary.weightedPrecision)\n",
    "print(Training_Summary.weightedFMeasure())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So, the recall rate and precision rate are also in the same range in the above calculations, which is shows target class was well balanced.\n",
    "# We can say that the model performance is good as  Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
